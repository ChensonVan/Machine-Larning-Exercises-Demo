### 9 Recommender Systems

#### 9.1 What is Recommender Systems

对于推荐系统的定义，我们先举几个例子来理解一下。

- 电影网站给用户推荐电影，可以根据该用户以往的评分，比如给浪漫爱情电影评分高，给动作片评分较低，那么系统可以根据这些信息，给用户推荐偏向浪漫爱情的电影
- 如果是新用户呢？我们没有该用户的评分信息。那么我们可以根据整个系统中，某些电影评分较高进行推荐
- 那么如果是新网站，新用户呢？

以上例子，我们可以把推荐系统分成两类。

- **Content-based systems**

  Content-based，就是基于已有的信息进行推荐。具体哪些信息呢？在上面的电影推荐系统中，有两类信息需要分析。

  ​

  第一，是User的评分信息，比如给爱情片评分高，给动作片评分低。

  第二，是Movie的特征信息，比如这部电影偏向爱情片多一些，但也有一部分搞笑。所以在A（爱情片）和B（搞笑片）中， A的权重更高，B的较低

  ​

  基于以上两部分信息，我们可以给用户推荐他所喜欢的电影。

  ![](http://p1.bpimg.com/567571/47a077979840183f.png)

  ​

- **Collaborative filterring systems**

  协同过滤器，则是基于用户/物品之间的相似度进行推荐的。即用户A和用户B都喜欢爱情、浪漫电影，我们就可以把用户A评分过的爱情浪漫电影，推荐给用户B。

  ![](http://p1.bpimg.com/567571/783c179fd4d4c3ff.png)



#### 9.2 Content-based systems

##### 9.2.1 Problem Analysis

以电影推荐系统为例，假设我们已经对系统中的电影特征有了较为完善，即我们知道某部电影属于爱情片多少分，属于动作片多少分。

那么我们现在以Alice为例，她对两部爱情片评分比较高，对于两部动作片评分为0。那么系统就可以给Alice推荐**偏向爱情浪漫的，且不怎么属于动作片**的电影。

| Movies               | Alice - θ(1) | Bob - θ(2) | Carol - θ(3) | Dave - θ(4) | romance - x1 | action -x2 |
| -------------------- | :----------: | :--------: | :----------: | :---------: | :----------: | :--------: |
| Love at last         |      5       |     5      |      0       |      0      |     1.0      |    0.0     |
| Romance forever      |      5       |     ?      |      ?       |      0      |     0.9      |    0.1     |
| Cute puppies of love |      ？       |     4      |      0       |      ?      |     0.99     |    0.01    |
| Nonstop car chases   |      0       |     0      |      5       |      4      |     0.0      |    1.0     |
| Sword vs. karate     |      0       |     0      |      5       |      ?      |     0.2      |    0.8     |



##### 9.2.2 Optimization Objective

实际上我们已经假设之前对所有电影的特征进行了统计，所以此时有电影特征向量X，以及用户对于电影的评分Y向量。根据此时已有的信息，我们需要求出theta的值。所以能够对于那么没有评分过的电影，根据theta和x求出分数y。

因为一开始theat的值是随机的，所以我们用**Linear Regression**的方法，不断减少cost function的值求出theta。

值得注意的是，因为这里是多个用户，每一个用户我们求出一个theta值。最后对于多个用户，我们需要求出多个**theta值**。

Actually, we can assume that we have known all features about the all movies, that is x1, x2, …, xn. And we want to initiate some random values for all theta for all users. As the feature values was fixed, we training the training set by minimizing cost function to get right value of theta.

![](http://p1.bqimg.com/567571/7480a00094b686af.png)

![](http://i1.piimg.com/567571/aa7db7ebd8562ccf.png)



##### 9.2.2 Gradient descent update

![](http://p1.bqimg.com/567571/fdc2b5b0affa21ef.png)

##### 9.2.3 Gradient descent in Logistic Regression

![](http://p1.bpimg.com/567571/9680507237900090.png)

Question:

1.   Why we don't need (1/m)?

     Anwser: As there are only ***one user***

	2. However, in the above example, we have known the values of all features, but for sometime, we have no idea about that. It means that we have to ***learn theta and features at the same time***



#### 9.3 Collaborative filtering

##### 9.3.1 Proble motivation

| Movies                     | Alice - θ(1) | Bob - θ(2) | Carol - θ(3) | Dave - θ(4) | romance - x1 | action - x2 |
| -------------------------- | :----------: | :--------: | :----------: | :---------: | :----------: | :---------: |
| x(1) - Love at last        |      5       |     5      |      0       |      0      |      ?       |      ?      |
| x(2) -Romance forever      |      5       |     ?      |      ?       |      0      |      ?       |      ?      |
| x(3) -Cute puppies of love |      ?       |     4      |      0       |      ?      |      ?       |      ?      |
| x(4) -Nonstop car chases   |      0       |     0      |      5       |      4      |      ?       |      ?      |
| x(5) -Sword vs. karate     |      0       |     0      |      5       |      ?      |      ?       |      ?      |



##### 9.3.2 How to do

- 在之前部分中，我们了解到了content-based，是**已知 x 和 y，求 theta**。

Assume:
$$
\theta^{(1)} = \begin{bmatrix} 0 \\ 5 \\ 0 \end{bmatrix},  \space\space
\theta^{(2)} = \begin{bmatrix} 0 \\ 5 \\ 0 \end{bmatrix},  \space\space
\theta^{(3)} = \begin{bmatrix} 0 \\ 0 \\ 5 \end{bmatrix},  \space\space
\theta^{(4)} = \begin{bmatrix} 0 \\ 0 \\ 5 \end{bmatrix},  \space\space
x^{(1)} = \begin{bmatrix} 1 \\ 1.0 \\ 0.0 \end{bmatrix}
$$
For Movie 1, we can calculate the result of Movie1 rating by all users.
$$
\theta^{(1)} * x^{(1)} \approx 5	\\
\theta^{(2)} * x^{(1)} \approx 5	\\
\theta^{(3)} * x^{(1)} \approx 0	\\
\theta^{(4)} * x^{(1)} \approx 0
$$

- 但是对于有些情况，我们并不知道x的特征值，该怎么办呢？

  逆向思考，我们也可以**通过 theat 和 y，来求 x 的值**。


- **那么对于 theta和x的值都不知道的情况下呢？**

| 对比特征  | Linear Regression | Collaborative filtering |
| :---: | :---------------: | :---------------------: |
| 特性向量X |       已知数据        |          待求解数据          |
| 权重 θ  |       待求解数据       |          待求解数据          |
|  y值   |       已知数据        |          已知数据           |



##### 9.3.3 Optimization Algorithm

- For a given value of theta, we can **minimize the cost function to learn the value of xi**


- For a given value of xi, we can also do that to **learn the value of theata**.

$$
θ -> x -> θ -> x -> θ -> x -> θ -> x -> ...
$$

Actually, these two steps are **Linear Regression**, we shoud do that **simultaneously** to update theta and x.

![](http://p1.bqimg.com/567571/fa32ae15048c3b75.png)



##### 9.3.4 Collaborative filtering Optimization Algorithm

![](http://p1.bqimg.com/567571/0afd72de7eca2c2d.png)

实际上，上面是两个 **LR**的问题，我们可以将上面两步合并到一起，这个就是**collaborative filterring**， 此时的optimizatino object 就从 J(theta) 和 J(X)  变为了 J(theta, X)。

![](http://p1.bpimg.com/567571/d14e3ed20060b507.png)



具体步骤如下

![](http://p1.bqimg.com/567571/5b7b9e072029ae09.png)



##### 9.3.5 Vectorization: Low rank matrix factorization

首先，我们先把评分Y用向量表示出来，同时表示为Theta和X两个矩阵的乘积
$$
Y= \begin{bmatrix} 5 & 5 & 0 & 0 \\ 5 & ? & ?& 0 \\ ? & 4 & 0 & ? \\ 0 & 0 & 5 & 4 \\ 0 &  0 & 5 & 0\end{bmatrix}  =
\begin{bmatrix}
(\theta^{(1)})^T(x^{(1)}) & (\theta^{(2)})^T(x^{(1)}) & ... & (\theta^{(n_u)})^T(x^{(1)}) \\
(\theta^{(1)})^T(x^{(2)}) & (\theta^{(2)})^T(x^{(2)}) & ... & (\theta^{(n_u)})^T(x^{(2)}) \\
... & ... & ... & ... \\
(\theta^{(1)})^T(x^{(n_m)}) & (\theta^{(2)})^T(x^{(n_m)}) & ... & (\theta^{(n_u)})^T(x^{(n_m)})
\end{bmatrix} = X * \Theta', R \in (n_m × n_u)
$$

$$
X = \begin{bmatrix} 
---(x^{(1)})^T--- 	\\
---(x^{(2)})^T---	\\
...	\\
---(x^{(n_m)})^T---
\end{bmatrix}, 
x^{(n_m)} = \begin{bmatrix} 
x^{(n_m)}_1 \\ x^{(n_m)}_2 \\ ... \\ x^{(n_m)}_n
\end{bmatrix}, R \in (n_m × n)
$$

$$
\Theta = \begin{bmatrix} 
---(\theta^{(1)})^T--- 	\\
---(\theta^{(2)})^T---	\\
...	\\
---(\theta^{(n_u)})^T---
\end{bmatrix}, 
\theta^{(n_u)} = \begin{bmatrix} 
\theta^{(n_u)}_1 \\ \theta^{(n_u)}_2 \\ ... \\ \theta^{(n_u)}_n
\end{bmatrix}, R \in (n_u × n)
$$

##### 9.3.6 Mean Normalization

对于那些新注册用户，系统中没有记录他们的偏好，则采用以下方法。

先计算出每部电影评分的平均值mu，然后把所有的评分都减去平均值（此后处理过的评分平均值为0）。虽然这样做对有评分记录用户是多余的，但却可以吧没有评分记录的用户给统一进来，避免全是0的情况。

![](http://i1.piimg.com/567571/cf1b4e1d7822228e.png)



#### 9.4 Implement Algorithm

##### 9.4.1  Cost Function without Regularization

![](http://p1.bpimg.com/567571/049268860c169449.png)

**Tips：**这里需要计算的只是针对那些已经评分过的电影，对于用户没有评分过的不需要计算。



##### 9.4.2 Collaborative filtering gradient		

![](http://p1.bqimg.com/567571/6d3b0fd8406f42e4.png)
$$
\frac {\partial J} {\partial x_k^{(1)}} , \frac {\partial J} {\partial x_k^{(2)}} , ..., \frac {\partial J} {\partial x_k^{(n_m)}} 	\space\space for \space each \space movie\\
\frac {\partial J} {\partial \theta_k^{(1)}} , \frac {\partial J} {\partial \theta_k^{(2)}} , ..., \frac {\partial J} {\partial \theta_k^{(n_u)}}	\space\space for \space each \space user
$$
**Tips：**

1. 对于使用vectorization方法，最终只有两个for-loop，一个计算X_grad，一个计算Theta_grad

2. 如何对X和Theta求**偏导数**？

![](http://p1.bqimg.com/567571/7a511dff9e71cea6.png)
$$
(Theta_{grad}(i, :))^T = \begin{bmatrix} 
\frac {\partial J} {\partial \theta^{(i)}_1} 	\\
\frac {\partial J} {\partial \theta^{(i)}_2}	\\
...	\\
\frac {\partial J} {\partial \theta^{(i)}_n}
\end{bmatrix}
$$

3. 同样，我们只需考虑用户已经评分过的电影，用其作为训练样本

4. 因为Vectorization非常容易搞乱各个matrix，所以建议先整理一下各个matrix的size，计算时可以根据matrix的size进行计算。

   ![](http://p1.bqimg.com/567571/0eb45a842e55e55f.png)



##### 9.4.3 Implementation

注意这里并没有给出完整的代码，都只是主要的部分。

```octave
% Theta : nu x n
% X     : nm x n
% Y     : nm x nu
% R     : nm x nu

pred = X * Theta';  %nm x nu    '
diff = pred - Y;

% Cost Function with regularization
J = 0.5 * sum(sum((diff.^2) .* R));
J = J + (lambda * 0.5) * sum(sum(Theta.^2));    % regularized term of theta.
J = J + (lambda * 0.5) * sum(sum(X.^2));        % regularized term of x.



% calculate X
for i = 1 : num_movies,
    % the row vector of all users that have rated movie i
    idx = find(R(i, :) == 1);   % (1 * r)

    % the list of users who have rated on movie i
    Theta_temp = Theta(idx, :); % (r * n)
    Y_temp = Y(i, idx);         % (1 * r)
    X_temp = X(i, :);           % (1 * n)

    %            ((1 * n) * (n * r)     -(1 * r)) * (r * n)  = (1 * n)
    X_grad(i, :) = (X_temp * Theta_temp' - Y_temp) * Theta_temp;   %'

    % regularization
    X_grad(i, :) = X_grad(i, :) + lambda * X_temp;
end


% calculate Theta
for i = 1 : num_users,
    % the row vector of all movies that user i has rated
    idx = find(R(:, i) == 1)';   % (1 * r)      '

    Theta_temp = Theta(i, :);   % (1 * n)
    Y_temp = Y(idx, i);         % (r * 1)
    X_temp = X(idx, :);         % (r * n)

    %                ((r * n) * (n * 1)     - (r * 1)) * (r * n) = (1 * n) 
    Theta_grad(i, :) = (X_temp * Theta_temp' - Y_temp)' * X_temp; 

    % regularization
    Theta_grad(i, :) = Theta_grad(i, :) + lambda * Theta_temp;
end

grad = [X_grad(:); Theta_grad(:)];
```


​			
​		
​	