### 4. Neural Networks

#### 4.1 Single Neurone

![](http://p1.bqimg.com/567571/7542318a01bb88f5.png)



![](http://i1.piimg.com/567571/04f80aca11bef7a0.png)







#### 4.2  Multiple Neurone

![](http://p1.bqimg.com/567571/7542318a01bb88f5.png)



**Input Layer —> Hidden Layer —> Output Layer**

In the previous picture, the values for each of the "activation" nodes is obtained as follows:
$$
a_k^{(i)} = g(z_k^{(i)}) = \theta_{k,0}^{i - 1}*x_0 + \theta_{k,1}^{i - 1}*x_1 + ... + \theta_{k,n}^{i - 1}*x_n  \\
z^{(i)} = \theta^{(i - 1)}*a^{(i - 1)}, \space where\space X = a^{(1)} \\
h_\theta(x) = a^{(i + 1)} = g(z^{(i + 1)})
$$
![](http://p1.bqimg.com/567571/628e44f9fe3a3150.png)

![](http://p1.bpimg.com/567571/1b90d5c6554c8051.png)

- To take care of the **extra bias uni**t add **a0 = 1** to a making it a **4x1 vector**

- **Foreard propagation**

  Forward propagate and calculate the activation of each layer sequentially.


- This is saying that we campute our activation nodes by using a **3x4** matrix of parameters. We apply each row of the parameters to our inputs to obtain the value for each one activation node.


- The output of hypothesis is the logistic function applied to the sum of the values of our activation nodes, which have been multiplied by yet another parameters matrix **theta(2)** containing the weights for our second layer of nodes.


- Each layer gets its own matrix of weights, **theta(j)**


- If network has **sj units** in layer j and sj+1 units in layer j+1, then Θ(j) will be of dimension **s_(j+1)×(s_j+1).** **1** should be **extra bias of unit**.

$$
\theta(j) \space will \space be \space of \space dimension \space s_{j+1} * (s_j + 1) 
$$

​	**e.g.** layer 1 has 2 input nodes and layer 2 has 4 activation nodes. Dimension of theta(1) is going ti be 4 x 3 where:
$$
s_j = 2, and \space s_{j+1} = 4, so \space s_{j+1} * (s_j + 1) = 4 * 3.
$$

- For last layer, that is **output layer** and that is a **2-dimension VECTOR**, like [1 0 0], [0 1 0], [0 0 1] rather than [1 2 3]

![](http://p1.bpimg.com/567571/4178a680767bfbb2.png)

![](http://p1.bpimg.com/567571/c4affc8ce35debae.png)



#### 4.3 Application

##### 4.3.1XOR / XNOR

##### 4.3.2 NOT

##### 4.3.3 XNOE

![](http://i1.piimg.com/567571/606bda75b6aa1c67.png)









